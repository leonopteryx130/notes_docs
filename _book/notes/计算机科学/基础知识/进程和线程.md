# 应用程序的进程和线程

对CPU的工作来说，进程和线程其实是一个目的，都是为了实现并发，站在CPU的角度，线程可以理解为颗粒度更细一点的进程。

进程很容易理解，也很直观，打开任务管理器，点击进程就能看到每个应用程序都有一个或者很多个进程，如下图：

<div align="center">
    <img src=./process1.png width=80% />
</div>

Google Chrome有70个进程，点击详细信息可以看到每个进程都有与之对应的pid:

<div align="center">
    <img src=./process2.png width=60% />
</div>

## **先说一下背景：**

我们的电脑是由CPU+RAM+各种其他资源组成的（比如显卡，光驱，键盘鼠标等），这些设备的运行和计算都要依靠CPU和RAM。但是这里有个非常基础的事实就是CPU太快了，读写速度是硬盘的数千数万倍，RAM和各种挂载设备根本跟不上CPU的速度，考虑到设备之间速度差异这么明显，挂载设备在CPU里轮流执行任务的效率是最高的，这种策略极大的提升了CPU的使用率。

## **引入一个重要的概念——上下文：**

上下文也就是一个进程要正常运行的所有状态信息，包括该进程在寄存器中的当前值，主存的内容等。因为为了保证CPU的高效运行，CPU只做计算，不做存储，当一个进程开始执行时候，将该进程的上下文交给寄存器，运算并更新后的值再保存到上下文，等待下一次执行的时候使用。

## **将这个过程串联起来：**

先加载进程A的上下文，再执行进程A，保存进程A的上下文，调入下一个要执行的进程B的进程上下文，然后开始执行B,保存进程B的上下文。

## **那么线程是什么呢？**

进程的颗粒度太大，每次执行都要进程上下文的切换，但是实际情况下，很多CPU任务是可以共享上下文的（比如同一个软件中同一个服务的上下文大多数都可以共享），但是绝大多数软件的执行都不可能是一条逻辑执行下去的，必定有多个分支和程序段，恰巧这些程序段的上下文可以共享，于是就出现了线程，同一个进程不同线程在cpu中轮流执行的时候，没有上下文切换时间的开销，进一步提高了运行效率。

## **执行流程**

假设现在有一个程序A要开始在CPU执行，程序A有两个进程M和N，M进程有3个线程a, b, c，N进程有2个线程d, e：

操作系统将权限交给程序A   ---->   CPU加载程序A(进程M)的上下文   ---->   
CPU执行进程M的a小段   ---->   CPU依次执行进程M的b, c小段   ---->    CPU切换上下文为进程N的上下文   ---->   CPU依次执行进程N的d, e小段 

每个线程有自己的栈 stack，记录该线程里面的方法相互调用的关系；但是一个进程里的所有线程是共用堆 heap（就是前边提到的进程上下文） 的。那么不同的进程之间是不可以互相访问内存的，每个进程有自己的内存空间 memeory space，也就是虚拟内存 virtual memory。通过这个虚拟内存，每一个进程都感觉自己拥有了整个内存空间。虚拟内存的机制，就是屏蔽了物理内存的限制。

## **为什么要有线程？**

每个进程都有自己的地址空间，即进程空间。进程间共享数据需要通过进程间通信（IPC），在进程间进行信息交换，性能开销较大。并且创建进程（一般是调用 fork 方法）的性能开销较大。
一个服务器通常需要接收大量并发请求，如果为每一个请求都创建一个进程，系统开销大、请求响应效率低，因此操作系统引进线程。

## **Tip:**
这里的进程和线程的概念仅从CPU的角度分析，在程序实现角度，要对这个概念进行物化